import streamlit as st
from PIL import Image
import numpy as np
import tensorflow as tf
from gtts import gTTS
import io
import time

st.title("ğŸ”¬ í”¼ë¶€ì•” ì§„ë‹¨ ë³´ì¡° ì‹œìŠ¤í…œ")
st.warning("âš ï¸ ì´ ì„œë¹„ìŠ¤ëŠ” ì§„ë‹¨ ë³´ì¡° ë„êµ¬ë¡œ, ì˜ë£Œì§„ ìƒë‹´ì„ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# h5 ëª¨ë¸ ë¡œë”© (ìµœì´ˆ í•œ ë²ˆë§Œ)
@st.cache_resource
def load_model():
    return tf.keras.models.load_model('skin_cancer_models.h5')


model = load_model()


def preprocess_image(img):
    img = img.resize((224, 224))
    img_array = np.array(img)
    if img_array.shape[-1] == 4:
        img_array = img_array[..., :3]
    img_array = img_array / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    return img_array


def tts_gtts(text, lang='ko'):
    try:
        tts = gTTS(text=text, lang=lang)
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        return fp.read()
    except Exception as e:
        st.warning(f"TTS ë³€í™˜ ì˜¤ë¥˜: {str(e)}")
        return None


# ì±„íŒ… í˜•ì‹ UI
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! í”¼ë¶€ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì‹œë©´ AIê°€ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤."}
    ]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

uploaded_image = st.file_uploader("í”¼ë¶€ ì‚¬ì§„ ì—…ë¡œë“œ", type=['jpg', 'jpeg', 'png'])

if uploaded_image:
    image = Image.open(uploaded_image)
    st.image(image, caption="ì—…ë¡œë“œëœ í”¼ë¶€ ì‚¬ì§„", width=300)

    if st.button("ì§„ë‹¨ ë¶„ì„ ì‹œì‘"):
        progress_bar = st.progress(0, text="ì§„ë‹¨ ì´ˆê¸°í™” ì¤‘...")
        with st.spinner("AIê°€ í”¼ë¶€ ìƒíƒœë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤.."):
            try:
                progress_bar.progress(10, text="ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...")
                time.sleep(0.5)
                img_array = preprocess_image(image)

                progress_bar.progress(30, text="ëª¨ë¸ ì¶”ë¡  ì¤‘...")
                time.sleep(0.5)
                prediction = model.predict(img_array)[0]

                progress_bar.progress(80, text="ê²°ê³¼ í•´ì„ ì¤‘..")
                time.sleep(0.3)
                if len(prediction) == 2:
                    benign_prob = float(prediction[0])
                    malignant_prob = float(prediction[1])
                else:
                    malignant_prob = float(prediction)
                    benign_prob = 1.0 - malignant_prob

                benign_pct = int(benign_prob * 100)
                malignant_pct = int(malignant_prob * 100)
                if malignant_prob < 0.5:
                    result_msg = f"ì–‘ì„±ì¼ í™•ë¥ ì´ {benign_pct}%, ì•…ì„±ì¼ í™•ë¥ ì´ {malignant_pct}%ì…ë‹ˆë‹¤. í˜„ì¬ ê²°ê³¼ëŠ” ì–‘ì„±ì— ê°€ê¹ì§€ë§Œ, ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ í”¼ë¶€ê³¼ ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
                else:
                    result_msg = f"ì•…ì„± ê°€ëŠ¥ì„±ì´ {malignant_pct}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì¦‰ì‹œ í”¼ë¶€ê³¼ ì „ë¬¸ì˜ ìƒë‹´ì´ í•„ìš”í•©ë‹ˆë‹¤."

                progress_bar.progress(95, text="ìŒì„± ì•ˆë‚´ ìƒì„± ì¤‘...")
                time.sleep(0.8)

            except Exception as e:
                result_msg = f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}. ì˜¬ë°”ë¥¸ í”¼ë¶€ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”."

            st.session_state.messages.append({"role": "assistant", "content": result_msg})

            audio_bytes = tts_gtts(result_msg, lang='ko')
            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3")

            progress_bar.progress(100, text="ì§„ë‹¨ ì™„ë£Œ!")
            time.sleep(0.5)
            progress_bar.empty()

            st.rerun()
